{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8347ffcc",
   "metadata": {},
   "source": [
    "# Load the Pretrained Model and the dataset\n",
    "We use ernie-3.0-base-zh as the model and chnsenticorp as the dataset for example. More models can be found in [PaddleNLP Model Zoo](https://paddlenlp.readthedocs.io/zh/latest/model_zoo/transformers.html#transformer).\n",
    "\n",
    "Obviously, PaddleNLP is needed to run this notebook, which is easy to install:\n",
    "```bash\n",
    "pip install setuptools_scm \n",
    "pip install --upgrade paddlenlp\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "da04dafd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/pp2/lib/python3.7/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "\u001b[32m[2022-07-05 19:57:13,681] [    INFO]\u001b[0m - Already cached /root/.paddlenlp/models/ernie-3.0-base-zh/ernie_3.0_base_zh.pdparams\u001b[0m\n",
      "W0705 19:57:13.684257 149389 gpu_context.cc:278] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 11.2, Runtime API Version: 11.2\n",
      "W0705 19:57:13.688616 149389 gpu_context.cc:306] device: 0, cuDNN Version: 8.1.\n",
      "\u001b[32m[2022-07-05 19:57:23,465] [    INFO]\u001b[0m - Already cached /root/.paddlenlp/models/ernie-3.0-base-zh/ernie_3.0_base_zh_vocab.txt\u001b[0m\n",
      "\u001b[32m[2022-07-05 19:57:23,518] [    INFO]\u001b[0m - tokenizer config file saved in /root/.paddlenlp/models/ernie-3.0-base-zh/tokenizer_config.json\u001b[0m\n",
      "\u001b[32m[2022-07-05 19:57:23,520] [    INFO]\u001b[0m - Special tokens file saved in /root/.paddlenlp/models/ernie-3.0-base-zh/special_tokens_map.json\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import paddle\n",
    "import paddlenlp\n",
    "from assets.ernie import ErnieForSequenceClassification\n",
    "from paddlenlp.transformers import ErnieTokenizer\n",
    "\n",
    "MODEL_NAME = \"ernie-3.0-base-zh\"\n",
    "\n",
    "model = ErnieForSequenceClassification.from_pretrained(MODEL_NAME, num_classes=2)\n",
    "tokenizer = ErnieTokenizer.from_pretrained(MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "81628d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "from paddlenlp.datasets import load_dataset\n",
    "DATASET_NAME = 'chnsenticorp'\n",
    "train_ds, dev_ds, test_ds = load_dataset(\n",
    "    DATASET_NAME, splits=[\"train\", \"dev\", \"test\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ade19aa",
   "metadata": {},
   "source": [
    "# Prepare the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "affc4988",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "47563cd5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset labels: ['0', '1']\n",
      "dataset examples:\n",
      "{'text': '选择珠江花园的原因就是方便，有电动扶梯直接到达海边，周围餐馆、食廊、商场、超市、摊位一应俱全。酒店装修一般，但还算整洁。 泳池在大堂的屋顶，因此很小，不过女儿倒是喜欢。 包的早餐是西式的，还算丰富。 服务吗，一般', 'label': 1, 'qid': ''}\n",
      "{'text': '15.4寸笔记本的键盘确实爽，基本跟台式机差不多了，蛮喜欢数字小键盘，输数字特方便，样子也很美观，做工也相当不错', 'label': 1, 'qid': ''}\n",
      "{'text': '房间太小。其他的都一般。。。。。。。。。', 'label': 0, 'qid': ''}\n",
      "{'text': '1.接电源没有几分钟,电源适配器热的不行. 2.摄像头用不起来. 3.机盖的钢琴漆，手不能摸，一摸一个印. 4.硬盘分区不好办.', 'label': 0, 'qid': ''}\n",
      "{'text': '今天才知道这书还有第6卷,真有点郁闷:为什么同一套书有两种版本呢?当当网是不是该跟出版社商量商量,单独出个第6卷,让我们的孩子不会有所遗憾。', 'label': 1, 'qid': ''}\n",
      "Training Starts:\n",
      "global step 100, epoch: 1, batch: 100, loss: 0.13706, acc: 0.80875\n",
      "global step 200, epoch: 1, batch: 200, loss: 0.43083, acc: 0.85531\n",
      "global step 300, epoch: 1, batch: 300, loss: 0.09329, acc: 0.87771\n",
      "eval loss: 0.18998, accu: 0.93500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2022-07-04 19:10:15,094] [    INFO]\u001b[0m - tokenizer config file saved in assets/chnsenticorp-ernie-3.0-base-zh/tokenizer_config.json\u001b[0m\n",
      "\u001b[32m[2022-07-04 19:10:15,096] [    INFO]\u001b[0m - Special tokens file saved in assets/chnsenticorp-ernie-3.0-base-zh/special_tokens_map.json\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# training the model and save to save_dir\n",
    "# only needs to run once.\n",
    "# total steps ~900 (3 epochs)\n",
    "\n",
    "from assets.utils import training_model\n",
    "training_model(model, tokenizer, train_ds, dev_ds, save_dir=f'assets/{DATASET_NAME}-{MODEL_NAME}')\n",
    "\n",
    "# global step 900, epoch: 3, batch: 300, loss: 0.00739, acc: 0.98438\n",
    "# eval loss: 0.19582, accu: 0.94750"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ab7ab34",
   "metadata": {},
   "source": [
    "## Or Load the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "71b6f523",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load the trained model.\n",
    "state_dict = paddle.load(f'assets/{DATASET_NAME}-{MODEL_NAME}/model_state.pdparams')\n",
    "model.set_dict(state_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e7ab06a",
   "metadata": {},
   "source": [
    "# Prepare for Interpretations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d7ee58f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import interpretdl as it\n",
    "import numpy as np\n",
    "from assets.utils import convert_example, aggregate_subwords_and_importances\n",
    "from paddlenlp.data import Stack, Tuple, Pad\n",
    "from interpretdl.data_processor.visualizer import VisualizationTextRecord, visualize_text\n",
    "\n",
    "def preprocess_fn(data):\n",
    "    examples = []\n",
    "    \n",
    "    if not isinstance(data, list):\n",
    "        data = [data]\n",
    "    \n",
    "    for text in data:\n",
    "        input_ids, segment_ids = convert_example(\n",
    "            text,\n",
    "            tokenizer,\n",
    "            max_seq_length=128,\n",
    "            is_test=True\n",
    "        )\n",
    "        examples.append((input_ids, segment_ids))\n",
    "\n",
    "    batchify_fn = lambda samples, fn=Tuple(\n",
    "        Pad(axis=0, pad_val=tokenizer.pad_token_id),  # input id\n",
    "        Pad(axis=0, pad_val=tokenizer.pad_token_id),  # segment id\n",
    "    ): fn(samples)\n",
    "    \n",
    "    input_ids, segment_ids = batchify_fn(examples)\n",
    "    return paddle.to_tensor(input_ids, stop_gradient=False), paddle.to_tensor(segment_ids, stop_gradient=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b771aa3",
   "metadata": {},
   "source": [
    "## BT Interpreter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3451fa50-6ea3-452a-9ac7-1609b81ee689",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Token-wise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bf7c7c2b-1f46-4b18-8e45-a16c424e8da8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data: {'text': '这个宾馆比较陈旧了，特价的房间也很一般。总体来说一般'} \t Lable: negative\n"
     ]
    }
   ],
   "source": [
    "from assets.utils import predict\n",
    "\n",
    "data = [\n",
    "    {\"text\":'这个宾馆比较陈旧了，特价的房间也很一般。总体来说一般'},\n",
    "#     {\"text\":'怀着十分激动的心情放映，可是看着看着发现，在放映完毕后，出现一集米老鼠的动画片'},\n",
    "#     {\"text\":'作为老的四星酒店，房间依然很整洁，相当不错。机场接机服务很好，可以在车上办理入住手续，节省时间。'},\n",
    "]\n",
    "\n",
    "label_map = {0: 'negative', 1: 'positive'}\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "results = predict(\n",
    "    model, data, tokenizer, label_map, batch_size=batch_size)\n",
    "\n",
    "for idx, text in enumerate(data):\n",
    "    print('Data: {} \\t Lable: {}'.format(text, results[idx]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a333d08f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table width: 100%><tr><th>True Label</th><th>Predicted Label (Prob)</th><th>Target Label</th><th>Word Importance</th><tr><td><text style=\"padding-right:2em\"><b>0</b></text></td><td><text style=\"padding-right:2em\"><b>0 (1.37)</b></text></td><td><text style=\"padding-right:2em\"><b>0</b></text></td><td><mark style=\"background-color: hsl(120, 75%, 86%); opacity:1.0;                         line-height:1.75\"><font color=\"black\"> 这                        </font></mark><mark style=\"background-color: hsl(120, 75%, 93%); opacity:1.0;                         line-height:1.75\"><font color=\"black\"> 个                        </font></mark><mark style=\"background-color: hsl(120, 75%, 94%); opacity:1.0;                         line-height:1.75\"><font color=\"black\"> 宾                        </font></mark><mark style=\"background-color: hsl(120, 75%, 88%); opacity:1.0;                         line-height:1.75\"><font color=\"black\"> 馆                        </font></mark><mark style=\"background-color: hsl(120, 75%, 93%); opacity:1.0;                         line-height:1.75\"><font color=\"black\"> 比                        </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                         line-height:1.75\"><font color=\"black\"> 较                        </font></mark><mark style=\"background-color: hsl(120, 75%, 96%); opacity:1.0;                         line-height:1.75\"><font color=\"black\"> 陈                        </font></mark><mark style=\"background-color: hsl(120, 75%, 97%); opacity:1.0;                         line-height:1.75\"><font color=\"black\"> 旧                        </font></mark><mark style=\"background-color: hsl(120, 75%, 92%); opacity:1.0;                         line-height:1.75\"><font color=\"black\"> 了                        </font></mark><mark style=\"background-color: hsl(120, 75%, 85%); opacity:1.0;                         line-height:1.75\"><font color=\"black\"> ，                        </font></mark><mark style=\"background-color: hsl(120, 75%, 97%); opacity:1.0;                         line-height:1.75\"><font color=\"black\"> 特                        </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                         line-height:1.75\"><font color=\"black\"> 价                        </font></mark><mark style=\"background-color: hsl(120, 75%, 95%); opacity:1.0;                         line-height:1.75\"><font color=\"black\"> 的                        </font></mark><mark style=\"background-color: hsl(120, 75%, 97%); opacity:1.0;                         line-height:1.75\"><font color=\"black\"> 房                        </font></mark><mark style=\"background-color: hsl(120, 75%, 98%); opacity:1.0;                         line-height:1.75\"><font color=\"black\"> 间                        </font></mark><mark style=\"background-color: hsl(120, 75%, 94%); opacity:1.0;                         line-height:1.75\"><font color=\"black\"> 也                        </font></mark><mark style=\"background-color: hsl(120, 75%, 88%); opacity:1.0;                         line-height:1.75\"><font color=\"black\"> 很                        </font></mark><mark style=\"background-color: hsl(120, 75%, 90%); opacity:1.0;                         line-height:1.75\"><font color=\"black\"> 一                        </font></mark><mark style=\"background-color: hsl(120, 75%, 97%); opacity:1.0;                         line-height:1.75\"><font color=\"black\"> 般                        </font></mark><mark style=\"background-color: hsl(120, 75%, 83%); opacity:1.0;                         line-height:1.75\"><font color=\"black\"> 。                        </font></mark><mark style=\"background-color: hsl(120, 75%, 81%); opacity:1.0;                         line-height:1.75\"><font color=\"black\"> 总                        </font></mark><mark style=\"background-color: hsl(120, 75%, 96%); opacity:1.0;                         line-height:1.75\"><font color=\"black\"> 体                        </font></mark><mark style=\"background-color: hsl(120, 75%, 95%); opacity:1.0;                         line-height:1.75\"><font color=\"black\"> 来                        </font></mark><mark style=\"background-color: hsl(120, 75%, 97%); opacity:1.0;                         line-height:1.75\"><font color=\"black\"> 说                        </font></mark><mark style=\"background-color: hsl(120, 75%, 85%); opacity:1.0;                         line-height:1.75\"><font color=\"black\"> 一                        </font></mark><mark style=\"background-color: hsl(120, 75%, 86%); opacity:1.0;                         line-height:1.75\"><font color=\"black\"> 般                        </font></mark></td><tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "bt = it.BTNLPInterpreter(model, device='gpu:0')\n",
    "\n",
    "interp_class = 0\n",
    "pred = model(*preprocess_fn(data))\n",
    "subword_importances = bt.interpret(\n",
    "    ap_mode=\"token\",\n",
    "    data=preprocess_fn(data),\n",
    "    label=interp_class,\n",
    "    start_layer=9)\n",
    "\n",
    "true_label = 0\n",
    "recs = []\n",
    "\n",
    "subwords = \" \".join(tokenizer._tokenize(data[0]['text'])).split(' ')\n",
    "\n",
    "words, word_importances = aggregate_subwords_and_importances(subwords, subword_importances[0])\n",
    "word_importances = np.array(word_importances) / np.linalg.norm(\n",
    "        word_importances)\n",
    "    \n",
    "recs.append(\n",
    "        VisualizationTextRecord(words, word_importances, true_label,\n",
    "                               np.argmax(pred), pred[0, np.argmax(pred)].item(), interp_class)\n",
    "    )\n",
    "\n",
    "visualize_text(recs)\n",
    "# The visualization is not available at github"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf2f1c7a-6cfe-4dd3-a281-f60f59139c49",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Head-wise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "07260e49-ca68-489e-9485-5bf65a4592b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table width: 100%><tr><th>True Label</th><th>Predicted Label (Prob)</th><th>Target Label</th><th>Word Importance</th><tr><td><text style=\"padding-right:2em\"><b>0</b></text></td><td><text style=\"padding-right:2em\"><b>0 (1.37)</b></text></td><td><text style=\"padding-right:2em\"><b>0</b></text></td><td><mark style=\"background-color: hsl(120, 75%, 87%); opacity:1.0;                         line-height:1.75\"><font color=\"black\"> 这                        </font></mark><mark style=\"background-color: hsl(120, 75%, 97%); opacity:1.0;                         line-height:1.75\"><font color=\"black\"> 个                        </font></mark><mark style=\"background-color: hsl(120, 75%, 97%); opacity:1.0;                         line-height:1.75\"><font color=\"black\"> 宾                        </font></mark><mark style=\"background-color: hsl(120, 75%, 95%); opacity:1.0;                         line-height:1.75\"><font color=\"black\"> 馆                        </font></mark><mark style=\"background-color: hsl(120, 75%, 92%); opacity:1.0;                         line-height:1.75\"><font color=\"black\"> 比                        </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                         line-height:1.75\"><font color=\"black\"> 较                        </font></mark><mark style=\"background-color: hsl(120, 75%, 98%); opacity:1.0;                         line-height:1.75\"><font color=\"black\"> 陈                        </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                         line-height:1.75\"><font color=\"black\"> 旧                        </font></mark><mark style=\"background-color: hsl(120, 75%, 91%); opacity:1.0;                         line-height:1.75\"><font color=\"black\"> 了                        </font></mark><mark style=\"background-color: hsl(120, 75%, 80%); opacity:1.0;                         line-height:1.75\"><font color=\"black\"> ，                        </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                         line-height:1.75\"><font color=\"black\"> 特                        </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                         line-height:1.75\"><font color=\"black\"> 价                        </font></mark><mark style=\"background-color: hsl(120, 75%, 96%); opacity:1.0;                         line-height:1.75\"><font color=\"black\"> 的                        </font></mark><mark style=\"background-color: hsl(120, 75%, 98%); opacity:1.0;                         line-height:1.75\"><font color=\"black\"> 房                        </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                         line-height:1.75\"><font color=\"black\"> 间                        </font></mark><mark style=\"background-color: hsl(120, 75%, 95%); opacity:1.0;                         line-height:1.75\"><font color=\"black\"> 也                        </font></mark><mark style=\"background-color: hsl(120, 75%, 92%); opacity:1.0;                         line-height:1.75\"><font color=\"black\"> 很                        </font></mark><mark style=\"background-color: hsl(120, 75%, 93%); opacity:1.0;                         line-height:1.75\"><font color=\"black\"> 一                        </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                         line-height:1.75\"><font color=\"black\"> 般                        </font></mark><mark style=\"background-color: hsl(120, 75%, 79%); opacity:1.0;                         line-height:1.75\"><font color=\"black\"> 。                        </font></mark><mark style=\"background-color: hsl(120, 75%, 76%); opacity:1.0;                         line-height:1.75\"><font color=\"black\"> 总                        </font></mark><mark style=\"background-color: hsl(120, 75%, 94%); opacity:1.0;                         line-height:1.75\"><font color=\"black\"> 体                        </font></mark><mark style=\"background-color: hsl(120, 75%, 92%); opacity:1.0;                         line-height:1.75\"><font color=\"black\"> 来                        </font></mark><mark style=\"background-color: hsl(120, 75%, 96%); opacity:1.0;                         line-height:1.75\"><font color=\"black\"> 说                        </font></mark><mark style=\"background-color: hsl(120, 75%, 87%); opacity:1.0;                         line-height:1.75\"><font color=\"black\"> 一                        </font></mark><mark style=\"background-color: hsl(120, 75%, 90%); opacity:1.0;                         line-height:1.75\"><font color=\"black\"> 般                        </font></mark></td><tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "interp_class = 0\n",
    "pred = model(*preprocess_fn(data))\n",
    "subword_importances = bt.interpret(\n",
    "    data=preprocess_fn(data),\n",
    "    label=interp_class,\n",
    "    start_layer=11)\n",
    "\n",
    "true_label = 0\n",
    "recs = []\n",
    "\n",
    "subwords = \" \".join(tokenizer._tokenize(data[0]['text'])).split(' ')\n",
    "\n",
    "words, word_importances = aggregate_subwords_and_importances(subwords, subword_importances[0])\n",
    "word_importances = np.array(word_importances) / np.linalg.norm(\n",
    "        word_importances)\n",
    "    \n",
    "recs.append(\n",
    "        VisualizationTextRecord(words, word_importances, true_label,\n",
    "                               np.argmax(pred), pred[0, np.argmax(pred)].item(), interp_class)\n",
    "    )\n",
    "\n",
    "visualize_text(recs)\n",
    "# The visualization is not available at github"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4795154-b265-4176-9e0e-04d59e9ab070",
   "metadata": {},
   "source": [
    "## GA Interpreter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fb1ea522-d2a4-4ae2-9220-ec2ef53a4b7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data: {'text': '这个宾馆比较陈旧了，特价的房间也很一般。总体来说一般'} \t Lable: negative\n"
     ]
    }
   ],
   "source": [
    "from assets.utils import predict\n",
    "\n",
    "data = [\n",
    "    {\"text\":'这个宾馆比较陈旧了，特价的房间也很一般。总体来说一般'},\n",
    "#     {\"text\":'怀着十分激动的心情放映，可是看着看着发现，在放映完毕后，出现一集米老鼠的动画片'},\n",
    "#     {\"text\":'作为老的四星酒店，房间依然很整洁，相当不错。机场接机服务很好，可以在车上办理入住手续，节省时间。'},\n",
    "]\n",
    "\n",
    "label_map = {0: 'negative', 1: 'positive'}\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "results = predict(\n",
    "    model, data, tokenizer, label_map, batch_size=batch_size)\n",
    "\n",
    "for idx, text in enumerate(data):\n",
    "    print('Data: {} \\t Lable: {}'.format(text, results[idx]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8a780ccb-3442-4c9b-a769-2b6ba7b0e592",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table width: 100%><tr><th>True Label</th><th>Predicted Label (Prob)</th><th>Target Label</th><th>Word Importance</th><tr><td><text style=\"padding-right:2em\"><b>0</b></text></td><td><text style=\"padding-right:2em\"><b>0 (1.37)</b></text></td><td><text style=\"padding-right:2em\"><b>0</b></text></td><td><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                         line-height:1.75\"><font color=\"black\"> 这                        </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                         line-height:1.75\"><font color=\"black\"> 个                        </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                         line-height:1.75\"><font color=\"black\"> 宾                        </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                         line-height:1.75\"><font color=\"black\"> 馆                        </font></mark><mark style=\"background-color: hsl(120, 75%, 97%); opacity:1.0;                         line-height:1.75\"><font color=\"black\"> 比                        </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                         line-height:1.75\"><font color=\"black\"> 较                        </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                         line-height:1.75\"><font color=\"black\"> 陈                        </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                         line-height:1.75\"><font color=\"black\"> 旧                        </font></mark><mark style=\"background-color: hsl(120, 75%, 88%); opacity:1.0;                         line-height:1.75\"><font color=\"black\"> 了                        </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                         line-height:1.75\"><font color=\"black\"> ，                        </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                         line-height:1.75\"><font color=\"black\"> 特                        </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                         line-height:1.75\"><font color=\"black\"> 价                        </font></mark><mark style=\"background-color: hsl(120, 75%, 96%); opacity:1.0;                         line-height:1.75\"><font color=\"black\"> 的                        </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                         line-height:1.75\"><font color=\"black\"> 房                        </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                         line-height:1.75\"><font color=\"black\"> 间                        </font></mark><mark style=\"background-color: hsl(120, 75%, 90%); opacity:1.0;                         line-height:1.75\"><font color=\"black\"> 也                        </font></mark><mark style=\"background-color: hsl(120, 75%, 83%); opacity:1.0;                         line-height:1.75\"><font color=\"black\"> 很                        </font></mark><mark style=\"background-color: hsl(120, 75%, 82%); opacity:1.0;                         line-height:1.75\"><font color=\"black\"> 一                        </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                         line-height:1.75\"><font color=\"black\"> 般                        </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                         line-height:1.75\"><font color=\"black\"> 。                        </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                         line-height:1.75\"><font color=\"black\"> 总                        </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                         line-height:1.75\"><font color=\"black\"> 体                        </font></mark><mark style=\"background-color: hsl(120, 75%, 85%); opacity:1.0;                         line-height:1.75\"><font color=\"black\"> 来                        </font></mark><mark style=\"background-color: hsl(120, 75%, 90%); opacity:1.0;                         line-height:1.75\"><font color=\"black\"> 说                        </font></mark><mark style=\"background-color: hsl(120, 75%, 69%); opacity:1.0;                         line-height:1.75\"><font color=\"black\"> 一                        </font></mark><mark style=\"background-color: hsl(120, 75%, 85%); opacity:1.0;                         line-height:1.75\"><font color=\"black\"> 般                        </font></mark></td><tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "bt = it.GANLPInterpreter(model, device='gpu:0')\n",
    "\n",
    "interp_class = 0\n",
    "pred = model(*preprocess_fn(data))\n",
    "subword_importances = bt.interpret(\n",
    "    data=preprocess_fn(data),\n",
    "    label=interp_class,\n",
    "    start_layer=11)\n",
    "\n",
    "true_label = 0\n",
    "recs = []\n",
    "\n",
    "subwords = \" \".join(tokenizer._tokenize(data[0]['text'])).split(' ')\n",
    "\n",
    "words, word_importances = aggregate_subwords_and_importances(subwords, subword_importances[0])\n",
    "word_importances = np.array(word_importances) / np.linalg.norm(\n",
    "        word_importances)\n",
    "    \n",
    "recs.append(\n",
    "        VisualizationTextRecord(words, word_importances, true_label,\n",
    "                               np.argmax(pred), pred[0, np.argmax(pred)].item(), interp_class)\n",
    "    )\n",
    "\n",
    "visualize_text(recs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53259c5e-c196-458f-9716-b029effec65f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a77f6a7464ce9eaa05196aac170c6d9a8812f0d84e7e92f765cacaf98118350b"
  },
  "kernelspec": {
   "display_name": "pp2",
   "language": "python",
   "name": "pp2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
