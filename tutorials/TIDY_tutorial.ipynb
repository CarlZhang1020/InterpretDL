{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finding Mislabelled Samples through ResNet MNIST Training Process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook trains a ResNet model using MNIST dataset and employed TrainIng Data analYzer (TIDY) method based on Forgetting Events algorithm, specifically `ForgettingEventsInterpreter`, to investigate the training process by recording the predictions in the process. Some samples are manually mislabelled and we are able to find them by looking into the predictions along the training. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import paddle.fluid as fluid\n",
    "import paddle\n",
    "import numpy as np\n",
    "import sys\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import tarfile, pickle, itertools\n",
    "\n",
    "sys.path.append('..')\n",
    "import interpretdl as it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a ResNet architecture for MNIST, the code is borrowed from [PaddlePaddle Official Documentation](https://www.paddlepaddle.org.cn/documentation/docs/en/user_guides/cv_case/image_classification/README.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_bn_layer(input,\n",
    "                  ch_out,\n",
    "                  filter_size,\n",
    "                  stride,\n",
    "                  padding,\n",
    "                  act='relu',\n",
    "                  bias_attr=False):\n",
    "    tmp = fluid.layers.conv2d(\n",
    "        input=input,\n",
    "        filter_size=filter_size,\n",
    "        num_filters=ch_out,\n",
    "        stride=stride,\n",
    "        padding=padding,\n",
    "        act=None,\n",
    "        bias_attr=bias_attr)\n",
    "    return fluid.layers.batch_norm(input=tmp, act=act)\n",
    "\n",
    "\n",
    "def shortcut(input, ch_in, ch_out, stride):\n",
    "    if ch_in != ch_out:\n",
    "        return conv_bn_layer(input, ch_out, 1, stride, 0, None)\n",
    "    else:\n",
    "        return input\n",
    "\n",
    "\n",
    "def basicblock(input, ch_in, ch_out, stride):\n",
    "    tmp = conv_bn_layer(input, ch_out, 3, stride, 1)\n",
    "    tmp = conv_bn_layer(tmp, ch_out, 3, 1, 1, act=None, bias_attr=True)\n",
    "    short = shortcut(input, ch_in, ch_out, stride)\n",
    "    return fluid.layers.elementwise_add(x=tmp, y=short, act='relu')\n",
    "\n",
    "\n",
    "def layer_warp(block_func, input, ch_in, ch_out, count, stride):\n",
    "    tmp = block_func(input, ch_in, ch_out, stride)\n",
    "    for i in range(1, count):\n",
    "        tmp = block_func(tmp, ch_out, ch_out, 1)\n",
    "    return tmp\n",
    "\n",
    "\n",
    "def resnet_mnist(ipt, depth=32):\n",
    "    # depth should be one of 20, 32, 44, 56, 110, 1202\n",
    "    assert (depth - 2) % 6 == 0\n",
    "    n = (depth - 2) // 6\n",
    "    nStages = {16, 64, 128}\n",
    "    conv1 = conv_bn_layer(ipt, ch_out=16, filter_size=3, stride=1, padding=1)\n",
    "    res1 = layer_warp(basicblock, conv1, 16, 16, n, 1)\n",
    "    res2 = layer_warp(basicblock, res1, 16, 32, n, 2)\n",
    "    res3 = layer_warp(basicblock, res2, 32, 64, n, 2)\n",
    "    pool = fluid.layers.pool2d(\n",
    "        input=res3, pool_size=8, pool_type='avg', pool_stride=1)\n",
    "    predict = fluid.layers.fc(input=pool, size=10, act='softmax')\n",
    "    return predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the MNIST dataset generator from **paddle.dataset** API to get the labels and manually mislabel 1% samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset =  paddle.dataset.mnist.train()\n",
    "\n",
    "labels = []\n",
    "for data in dataset():\n",
    "    labels.append(data[-1])\n",
    "    \n",
    "for i in range(100, 60000, 100):\n",
    "    labels[i] = np.random.choice(np.delete(np.arange(10), labels[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a new data generator based on MNIST data generator. It pads the 28 * 28 images to 32 * 32 so that it fits the model and replaces 1% true labels by the wrong ones. \n",
    "\n",
    "**Important:** the data generator shoud generate the index of each sample as the first element so that each sample's behavior can be recorded according to its index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reader_prepare(datareader, new_labels):\n",
    "    def reader():\n",
    "        idx = 0\n",
    "        for data in datareader():\n",
    "            data = list(data)\n",
    "            data.insert(0, idx)\n",
    "            # replace true labels by wrong ones\n",
    "            if idx % 100  == 0:\n",
    "                data[-1] = new_labels[idx]\n",
    "            # padding\n",
    "            d = np.ones((32,32,1)) * -1\n",
    "            d[2:30, 2:30] = data[1].reshape((28,28,1))\n",
    "            data[1] = d.reshape(-1)\n",
    "            yield tuple(data)\n",
    "            idx += 1\n",
    "    return reader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up a data loader with batch size of 128, and an Adam optimizer for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128\n",
    "train_reader = paddle.batch(\n",
    "    reader_prepare(dataset, labels), batch_size=BATCH_SIZE)\n",
    "optimizer = fluid.optimizer.Adam(learning_rate=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First initialize the `ForgettingEventsInterpreter` and then start `interpret`ing the training process by training 100 epochs. \n",
    "\n",
    "*stats* is a dictionary that maps image index to predictions in the training process and if they are correct; *noisy_samples* is a list of mislabelled image ids. *stats* is saved at \"assets/stats.pkl\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training 100 epochs. This may take some time.\n",
      "| Epoch [100/100] Iter[469]\t\tLoss: 0.0001 Acc@1: 99.915%%"
     ]
    }
   ],
   "source": [
    "fe = it.ForgettingEventsInterpreter(resnet_cifar10, True, [3, 32, 32])\n",
    "\n",
    "epochs = 100\n",
    "print('Training %d epochs. This may take some time.' % epochs)\n",
    "stats, noisy_samples = fe.interpret(\n",
    "    train_reader,\n",
    "    optimizer,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    epochs=epochs,\n",
    "    noisy_labels=True,\n",
    "    save_path='assets')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the recall, precision and F1 for our found noisy samples. \n",
    "\n",
    "99.5% of mislabelled samples have been found and among those samples found, 82.7% are indeed mislabelled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall:  0.995\n",
      "Precision:  0.8268698060941828\n",
      "F1 Score:  0.9031770045385779\n"
     ]
    }
   ],
   "source": [
    "recall = np.sum([id_ % 100 == 0 for id_ in noisy_samples]) / (60000 / 100)\n",
    "precision = np.sum([id_ % 100 == 0 for id_ in noisy_samples]) / len(noisy_samples)\n",
    "print('Recall: ', recall)\n",
    "print('Precision: ', precision)\n",
    "print('F1 Score: ', 2 * (recall * precision) / (recall + precision))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
